---
title: "progettoHealth"
author: "io"
date: "2024-05-04"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	results = FALSE
)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(results = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```


```{r lib, echo = FALSE, message = FALSE, results = FALSE}
#install.packages("gvlma")
#install.packages("ggcorrplot")
library(ggcorrplot)
library(gvlma)
library(tidyverse)
library(ggExtra)
library(cowplot)
library(magrittr)
library(gtable)
library(lattice)
library(grid)
library(gridExtra)
library(corrplot)
library(ggplot2)
library(GGally)
library(MASS)
library(kableExtra)
library(tidymodels)
```


```{r load, echo = FALSE, results = FALSE, message = FALSE}
setwd("C:/Users/media/Desktop/SCUOLA/uni/III anno/II semestre/epidemiology/progetto")
data = read.csv("breast_cancer.csv", header = T, stringsAsFactors = T, sep = ",")
str(data)
dim(data)
```


```{r}
missing_values <- colSums(is.na(data))
print(missing_values)
```


```{r fig.height=10, fig.width=10}
corr_mat = cor(data[, -c(2)])  # matrice di correlazione
corr = round(corr_mat, 1)


cex.before <- par("cex")
par(mfrow=c(1, 1))
corrplot(
  corr_mat,
  method = "color",
  addCoef.col = 1,
  number.cex = 0.8,
  tl.cex = 0.6,
  tl.col = "black",
  col=colorRampPalette(c("black","white","red"))(1000),
  order = "AOE",
  addCoefasPercent = TRUE
)
par(cex = cex.before)
```

```{r}
data$diagnosis<-factor(data$diagnosis)
str(data$diagnosis)
```

```{r load, echo = FALSE, results = FALSE, message = FALSE}
data$diagnosis<-factor(data$diagnosis, labels=c("B","M"))
```

```{r fig.height=30, fig.width=40}
# Ottenere il numero di colonne nel dataframe
num_colonne <- ncol(data)

# Creare una lista vuota per memorizzare i plot
plots_list <- list()

# Creare un ciclo for per iterare su tutte le colonne tranne le prime due
for (i in 3:num_colonne) {
  
  # Creare il boxplot per la colonna i-esima
  plot <- ggplot(data = data, aes_string(x = "diagnosis", y = names(data)[i], color = "diagnosis")) + 
    geom_boxplot() +
    theme(legend.position = "none", text= element_text(size = 25))+
    labs(x = "", y = names(data)[i]) +
    scale_color_manual(labels = c("B", "F"), values = c("darkorange", "cyan4")) 
  
    
  # Aggiungere il plot alla lista
  plots_list[[i-2]] <- plot
}

# Creare una griglia di plot utilizzando facet_wrap
grid_plot <- do.call(gridExtra::grid.arrange, c(plots_list, ncol = 5))

# Visualizzare la griglia di plot
grid_plot
```

```{r}
ggplot(data, aes(x=concave.points_worst, y=radius_mean, color= diagnosis))+
  geom_point()
```

```{r}
ggplot(data, aes(x=concave.points_worst, y=area_worst, color= diagnosis))+
  geom_point()
```

```{r}
ggplot(data, aes(x=concave.points_mean, y=radius_mean, color= diagnosis))+
  geom_point()
```
```{r}
# Split data into train and test
set.seed(2)
split <- initial_split(data, prop = 0.75, strata = NULL)
train <- split %>% 
         training()
test <- split %>% 
        testing()
```

```{r}
# Fit the model using the optimal hyperparameters
log_reg <- logistic_reg(penalty = 0.0000000001, mixture = 0) %>%
                 set_engine("glmnet") %>%
                 set_mode("classification") %>%
                 fit(diagnosis ~ radius_mean + concave.points_mean, data = train)

# Evaluate the model performance on the testing set
pred_class <- predict(log_reg, new_data = test, type = "class")

# Class Probabilities
pred_proba <- predict(log_reg, new_data = test, type = "prob")

results <- test %>%
  dplyr::select(diagnosis) %>%
  bind_cols(pred_class, pred_proba)

# Create confusion matrix
conf_mat(results, truth = diagnosis,
         estimate = .pred_class)
```
```{r}
coeff <- tidy(log_reg) %>% 
  arrange(desc(abs(estimate)))
print(coeff)
```

```{r}
# higher precision means that an algorithm returns more relevant results than irrelevant ones
precision(results, truth = diagnosis,
          estimate = .pred_class)
```
```{r}
# high recall means that an algorithm returns most of the relevant results
recall(results, truth = diagnosis, estimate = .pred_class)
```
